{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers, optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseMapNum = 32\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    \n",
    "    model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "batch_size = 64\n",
    "epochs=25\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "781/781 [==============================] - 432s 553ms/step - loss: 1.9304 - accuracy: 0.4258 - val_loss: 1.6406 - val_accuracy: 0.5506\n",
      "Epoch 2/75\n",
      "781/781 [==============================] - 430s 551ms/step - loss: 1.3156 - accuracy: 0.5839 - val_loss: 1.1456 - val_accuracy: 0.6547\n",
      "Epoch 3/75\n",
      "781/781 [==============================] - 431s 552ms/step - loss: 1.1228 - accuracy: 0.6473 - val_loss: 1.0647 - val_accuracy: 0.6978\n",
      "Epoch 4/75\n",
      "781/781 [==============================] - 450s 577ms/step - loss: 1.0125 - accuracy: 0.6857 - val_loss: 0.8494 - val_accuracy: 0.7421\n",
      "Epoch 5/75\n",
      "781/781 [==============================] - 485s 620ms/step - loss: 0.9262 - accuracy: 0.7129 - val_loss: 0.7864 - val_accuracy: 0.7700\n",
      "Epoch 6/75\n",
      "781/781 [==============================] - 482s 618ms/step - loss: 0.8798 - accuracy: 0.7330 - val_loss: 0.9418 - val_accuracy: 0.7346\n",
      "Epoch 7/75\n",
      "781/781 [==============================] - 481s 616ms/step - loss: 0.8317 - accuracy: 0.7482 - val_loss: 0.8484 - val_accuracy: 0.7545\n",
      "Epoch 8/75\n",
      "781/781 [==============================] - 296s 380ms/step - loss: 0.8082 - accuracy: 0.7608 - val_loss: 0.7713 - val_accuracy: 0.7910\n",
      "Epoch 9/75\n",
      "781/781 [==============================] - 232s 297ms/step - loss: 0.7834 - accuracy: 0.7689 - val_loss: 0.7469 - val_accuracy: 0.7913\n",
      "Epoch 10/75\n",
      "781/781 [==============================] - 230s 294ms/step - loss: 0.7604 - accuracy: 0.7781 - val_loss: 0.7915 - val_accuracy: 0.7803\n",
      "Epoch 11/75\n",
      "781/781 [==============================] - 266s 341ms/step - loss: 0.7504 - accuracy: 0.7831 - val_loss: 0.6903 - val_accuracy: 0.8120\n",
      "Epoch 12/75\n",
      "781/781 [==============================] - 274s 351ms/step - loss: 0.7378 - accuracy: 0.7892 - val_loss: 0.6580 - val_accuracy: 0.8218\n",
      "Epoch 13/75\n",
      "781/781 [==============================] - 298s 382ms/step - loss: 0.7244 - accuracy: 0.7942 - val_loss: 0.7230 - val_accuracy: 0.8017\n",
      "Epoch 14/75\n",
      "781/781 [==============================] - 278s 356ms/step - loss: 0.7109 - accuracy: 0.7990 - val_loss: 0.6855 - val_accuracy: 0.8138\n",
      "Epoch 15/75\n",
      "781/781 [==============================] - 271s 347ms/step - loss: 0.7022 - accuracy: 0.8019 - val_loss: 0.6456 - val_accuracy: 0.8278\n",
      "Epoch 16/75\n",
      "781/781 [==============================] - 278s 356ms/step - loss: 0.6931 - accuracy: 0.8053 - val_loss: 0.6342 - val_accuracy: 0.8344\n",
      "Epoch 17/75\n",
      "781/781 [==============================] - 276s 354ms/step - loss: 0.6828 - accuracy: 0.8077 - val_loss: 0.6452 - val_accuracy: 0.8285\n",
      "Epoch 18/75\n",
      "781/781 [==============================] - 238s 305ms/step - loss: 0.6726 - accuracy: 0.8146 - val_loss: 0.6291 - val_accuracy: 0.8386\n",
      "Epoch 19/75\n",
      "781/781 [==============================] - 256s 328ms/step - loss: 0.6704 - accuracy: 0.8158 - val_loss: 0.6615 - val_accuracy: 0.8234\n",
      "Epoch 20/75\n",
      "781/781 [==============================] - 259s 331ms/step - loss: 0.6631 - accuracy: 0.8182 - val_loss: 0.7393 - val_accuracy: 0.8035\n",
      "Epoch 21/75\n",
      "781/781 [==============================] - 297s 380ms/step - loss: 0.6604 - accuracy: 0.8198 - val_loss: 0.6560 - val_accuracy: 0.8264\n",
      "Epoch 22/75\n",
      "781/781 [==============================] - 251s 321ms/step - loss: 0.6528 - accuracy: 0.8244 - val_loss: 0.6025 - val_accuracy: 0.8472\n",
      "Epoch 23/75\n",
      "781/781 [==============================] - 249s 319ms/step - loss: 0.6563 - accuracy: 0.8222 - val_loss: 0.6037 - val_accuracy: 0.8445\n",
      "Epoch 24/75\n",
      "781/781 [==============================] - 256s 328ms/step - loss: 0.6463 - accuracy: 0.8261 - val_loss: 0.6110 - val_accuracy: 0.8408\n",
      "Epoch 25/75\n",
      "781/781 [==============================] - 243s 312ms/step - loss: 0.6447 - accuracy: 0.8272 - val_loss: 0.6614 - val_accuracy: 0.8321\n",
      "Epoch 26/75\n",
      "781/781 [==============================] - 229s 293ms/step - loss: 0.6459 - accuracy: 0.8288 - val_loss: 0.6335 - val_accuracy: 0.8397\n",
      "Epoch 27/75\n",
      "781/781 [==============================] - 231s 295ms/step - loss: 0.6385 - accuracy: 0.8304 - val_loss: 0.6266 - val_accuracy: 0.8415\n",
      "Epoch 28/75\n",
      "781/781 [==============================] - 235s 301ms/step - loss: 0.6327 - accuracy: 0.8346 - val_loss: 0.6798 - val_accuracy: 0.8219\n",
      "Epoch 29/75\n",
      "781/781 [==============================] - 234s 299ms/step - loss: 0.6312 - accuracy: 0.8319 - val_loss: 0.6474 - val_accuracy: 0.8355\n",
      "Epoch 30/75\n",
      "781/781 [==============================] - 237s 304ms/step - loss: 0.6283 - accuracy: 0.8340 - val_loss: 0.6870 - val_accuracy: 0.8249\n",
      "Epoch 31/75\n",
      "781/781 [==============================] - 235s 301ms/step - loss: 0.6294 - accuracy: 0.8338 - val_loss: 0.5663 - val_accuracy: 0.8631\n",
      "Epoch 32/75\n",
      "781/781 [==============================] - 234s 300ms/step - loss: 0.6255 - accuracy: 0.8350 - val_loss: 0.6292 - val_accuracy: 0.8416\n",
      "Epoch 33/75\n",
      "781/781 [==============================] - 234s 300ms/step - loss: 0.6212 - accuracy: 0.8387 - val_loss: 0.6502 - val_accuracy: 0.8365\n",
      "Epoch 34/75\n",
      "781/781 [==============================] - 235s 300ms/step - loss: 0.6263 - accuracy: 0.8369 - val_loss: 0.5547 - val_accuracy: 0.8644\n",
      "Epoch 35/75\n",
      "781/781 [==============================] - 233s 298ms/step - loss: 0.6144 - accuracy: 0.8383 - val_loss: 0.5788 - val_accuracy: 0.8566\n",
      "Epoch 36/75\n",
      "781/781 [==============================] - 227s 291ms/step - loss: 0.6190 - accuracy: 0.8391 - val_loss: 0.5944 - val_accuracy: 0.8513\n",
      "Epoch 37/75\n",
      "781/781 [==============================] - 229s 294ms/step - loss: 0.6129 - accuracy: 0.8401 - val_loss: 0.6689 - val_accuracy: 0.8354\n",
      "Epoch 38/75\n",
      "781/781 [==============================] - 240s 308ms/step - loss: 0.6096 - accuracy: 0.8416 - val_loss: 0.5808 - val_accuracy: 0.8590\n",
      "Epoch 39/75\n",
      "781/781 [==============================] - 224s 286ms/step - loss: 0.6155 - accuracy: 0.8402 - val_loss: 0.6386 - val_accuracy: 0.8364\n",
      "Epoch 40/75\n",
      "781/781 [==============================] - 245s 313ms/step - loss: 0.6097 - accuracy: 0.8421 - val_loss: 0.5859 - val_accuracy: 0.8563\n",
      "Epoch 41/75\n",
      "781/781 [==============================] - 249s 318ms/step - loss: 0.6113 - accuracy: 0.8420 - val_loss: 0.5904 - val_accuracy: 0.8527\n",
      "Epoch 42/75\n",
      "781/781 [==============================] - 241s 308ms/step - loss: 0.6083 - accuracy: 0.8421 - val_loss: 0.6271 - val_accuracy: 0.8373\n",
      "Epoch 43/75\n",
      "781/781 [==============================] - 227s 291ms/step - loss: 0.6055 - accuracy: 0.8463 - val_loss: 0.6344 - val_accuracy: 0.8380\n",
      "Epoch 44/75\n",
      "781/781 [==============================] - 230s 294ms/step - loss: 0.6071 - accuracy: 0.8440 - val_loss: 0.6335 - val_accuracy: 0.8457\n",
      "Epoch 45/75\n",
      "781/781 [==============================] - 232s 296ms/step - loss: 0.6028 - accuracy: 0.8473 - val_loss: 0.6504 - val_accuracy: 0.8350\n",
      "Epoch 46/75\n",
      "781/781 [==============================] - 233s 298ms/step - loss: 0.5954 - accuracy: 0.8473 - val_loss: 0.5908 - val_accuracy: 0.8524\n",
      "Epoch 47/75\n",
      "781/781 [==============================] - 233s 299ms/step - loss: 0.6020 - accuracy: 0.8463 - val_loss: 0.5912 - val_accuracy: 0.8541\n",
      "Epoch 48/75\n",
      "781/781 [==============================] - 233s 299ms/step - loss: 0.6000 - accuracy: 0.8470 - val_loss: 0.6466 - val_accuracy: 0.8367\n",
      "Epoch 49/75\n",
      "781/781 [==============================] - 233s 298ms/step - loss: 0.6009 - accuracy: 0.8471 - val_loss: 0.6073 - val_accuracy: 0.8486\n",
      "Epoch 50/75\n",
      "781/781 [==============================] - 247s 316ms/step - loss: 0.5958 - accuracy: 0.8475 - val_loss: 0.5879 - val_accuracy: 0.8556\n",
      "Epoch 51/75\n",
      "781/781 [==============================] - 249s 319ms/step - loss: 0.5978 - accuracy: 0.8484 - val_loss: 0.6734 - val_accuracy: 0.8317\n",
      "Epoch 52/75\n",
      "781/781 [==============================] - 241s 309ms/step - loss: 0.5932 - accuracy: 0.8495 - val_loss: 0.6985 - val_accuracy: 0.8308\n",
      "Epoch 53/75\n",
      "781/781 [==============================] - 238s 305ms/step - loss: 0.5919 - accuracy: 0.8496 - val_loss: 0.5901 - val_accuracy: 0.8575\n",
      "Epoch 54/75\n",
      "781/781 [==============================] - 239s 306ms/step - loss: 0.5947 - accuracy: 0.8479 - val_loss: 0.5948 - val_accuracy: 0.8570\n",
      "Epoch 55/75\n",
      "781/781 [==============================] - 237s 304ms/step - loss: 0.5890 - accuracy: 0.8509 - val_loss: 0.6160 - val_accuracy: 0.8504\n",
      "Epoch 56/75\n",
      "781/781 [==============================] - 248s 317ms/step - loss: 0.5860 - accuracy: 0.8522 - val_loss: 0.5805 - val_accuracy: 0.8606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/75\n",
      "781/781 [==============================] - 234s 300ms/step - loss: 0.5888 - accuracy: 0.8515 - val_loss: 0.5843 - val_accuracy: 0.8554\n",
      "Epoch 58/75\n",
      "781/781 [==============================] - 233s 299ms/step - loss: 0.5940 - accuracy: 0.8501 - val_loss: 0.6127 - val_accuracy: 0.8519\n",
      "Epoch 59/75\n",
      "781/781 [==============================] - 235s 301ms/step - loss: 0.5884 - accuracy: 0.8511 - val_loss: 0.6317 - val_accuracy: 0.8464\n",
      "Epoch 60/75\n",
      "781/781 [==============================] - 237s 303ms/step - loss: 0.5887 - accuracy: 0.8516 - val_loss: 0.6534 - val_accuracy: 0.8367\n",
      "Epoch 61/75\n",
      "781/781 [==============================] - 244s 313ms/step - loss: 0.5907 - accuracy: 0.8506 - val_loss: 0.5674 - val_accuracy: 0.8643\n",
      "Epoch 62/75\n",
      "781/781 [==============================] - 244s 312ms/step - loss: 0.5839 - accuracy: 0.8533 - val_loss: 0.6607 - val_accuracy: 0.8380\n",
      "Epoch 63/75\n",
      "781/781 [==============================] - 239s 306ms/step - loss: 0.5846 - accuracy: 0.8521 - val_loss: 0.6056 - val_accuracy: 0.8512\n",
      "Epoch 64/75\n",
      "781/781 [==============================] - 236s 302ms/step - loss: 0.5834 - accuracy: 0.8534 - val_loss: 0.6816 - val_accuracy: 0.8316\n",
      "Epoch 65/75\n",
      "781/781 [==============================] - 235s 301ms/step - loss: 0.5810 - accuracy: 0.8538 - val_loss: 0.6179 - val_accuracy: 0.8492\n",
      "Epoch 66/75\n",
      "781/781 [==============================] - 237s 303ms/step - loss: 0.5817 - accuracy: 0.8544 - val_loss: 0.5417 - val_accuracy: 0.8744\n",
      "Epoch 67/75\n",
      "781/781 [==============================] - 236s 302ms/step - loss: 0.5897 - accuracy: 0.8505 - val_loss: 0.5839 - val_accuracy: 0.8567\n",
      "Epoch 68/75\n",
      "781/781 [==============================] - 232s 297ms/step - loss: 0.5809 - accuracy: 0.8550 - val_loss: 0.5786 - val_accuracy: 0.8601\n",
      "Epoch 69/75\n",
      "781/781 [==============================] - 234s 299ms/step - loss: 0.5820 - accuracy: 0.8541 - val_loss: 0.5889 - val_accuracy: 0.8568\n",
      "Epoch 70/75\n",
      "781/781 [==============================] - 239s 306ms/step - loss: 0.5796 - accuracy: 0.8557 - val_loss: 0.5837 - val_accuracy: 0.8637\n",
      "Epoch 71/75\n",
      "781/781 [==============================] - 238s 305ms/step - loss: 0.5733 - accuracy: 0.8585 - val_loss: 0.6215 - val_accuracy: 0.8483\n",
      "Epoch 72/75\n",
      "781/781 [==============================] - 236s 302ms/step - loss: 0.5784 - accuracy: 0.8547 - val_loss: 0.6457 - val_accuracy: 0.8423\n",
      "Epoch 73/75\n",
      "781/781 [==============================] - 237s 304ms/step - loss: 0.5788 - accuracy: 0.8562 - val_loss: 0.5627 - val_accuracy: 0.8656\n",
      "Epoch 74/75\n",
      "781/781 [==============================] - 236s 302ms/step - loss: 0.5729 - accuracy: 0.8565 - val_loss: 0.6121 - val_accuracy: 0.8490\n",
      "Epoch 75/75\n",
      "781/781 [==============================] - 238s 304ms/step - loss: 0.5752 - accuracy: 0.8548 - val_loss: 0.6264 - val_accuracy: 0.8447\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=3*epochs,\n",
    "                    verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('savedmodels/model6_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "781/781 [==============================] - 242s 310ms/step - loss: 0.5373 - accuracy: 0.8689 - val_loss: 0.5442 - val_accuracy: 0.8744\n",
      "Epoch 2/25\n",
      "781/781 [==============================] - 236s 302ms/step - loss: 0.5174 - accuracy: 0.8728 - val_loss: 0.5427 - val_accuracy: 0.8720\n",
      "Epoch 3/25\n",
      "781/781 [==============================] - 237s 303ms/step - loss: 0.5101 - accuracy: 0.8754 - val_loss: 0.4960 - val_accuracy: 0.8820\n",
      "Epoch 4/25\n",
      "781/781 [==============================] - 241s 308ms/step - loss: 0.5029 - accuracy: 0.8770 - val_loss: 0.5570 - val_accuracy: 0.8626\n",
      "Epoch 5/25\n",
      "781/781 [==============================] - 246s 315ms/step - loss: 0.4970 - accuracy: 0.8780 - val_loss: 0.5289 - val_accuracy: 0.8748\n",
      "Epoch 6/25\n",
      "781/781 [==============================] - 238s 305ms/step - loss: 0.4977 - accuracy: 0.8768 - val_loss: 0.5660 - val_accuracy: 0.8629\n",
      "Epoch 7/25\n",
      "781/781 [==============================] - 235s 301ms/step - loss: 0.4898 - accuracy: 0.8795 - val_loss: 0.5221 - val_accuracy: 0.8763\n",
      "Epoch 8/25\n",
      "781/781 [==============================] - 236s 302ms/step - loss: 0.4863 - accuracy: 0.8790 - val_loss: 0.5210 - val_accuracy: 0.8746\n",
      "Epoch 9/25\n",
      "781/781 [==============================] - 240s 308ms/step - loss: 0.4879 - accuracy: 0.8787 - val_loss: 0.5389 - val_accuracy: 0.8710\n",
      "Epoch 10/25\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 0.4814 - accuracy: 0.8803 - val_loss: 0.5033 - val_accuracy: 0.8773\n",
      "Epoch 11/25\n",
      "781/781 [==============================] - 237s 303ms/step - loss: 0.4782 - accuracy: 0.8802 - val_loss: 0.4875 - val_accuracy: 0.8812\n",
      "Epoch 12/25\n",
      "781/781 [==============================] - 249s 318ms/step - loss: 0.4764 - accuracy: 0.8802 - val_loss: 0.4935 - val_accuracy: 0.8832\n",
      "Epoch 13/25\n",
      "781/781 [==============================] - 249s 318ms/step - loss: 0.4753 - accuracy: 0.8804 - val_loss: 0.5147 - val_accuracy: 0.8771\n",
      "Epoch 14/25\n",
      "781/781 [==============================] - 247s 316ms/step - loss: 0.4733 - accuracy: 0.8807 - val_loss: 0.5645 - val_accuracy: 0.8603\n",
      "Epoch 15/25\n",
      "781/781 [==============================] - 246s 314ms/step - loss: 0.4702 - accuracy: 0.8828 - val_loss: 0.4980 - val_accuracy: 0.8786\n",
      "Epoch 16/25\n",
      "781/781 [==============================] - 247s 316ms/step - loss: 0.4737 - accuracy: 0.8807 - val_loss: 0.4986 - val_accuracy: 0.8793\n",
      "Epoch 17/25\n",
      "781/781 [==============================] - 241s 309ms/step - loss: 0.4663 - accuracy: 0.8833 - val_loss: 0.5104 - val_accuracy: 0.8767\n",
      "Epoch 18/25\n",
      "781/781 [==============================] - 247s 317ms/step - loss: 0.4702 - accuracy: 0.8804 - val_loss: 0.5355 - val_accuracy: 0.8664\n",
      "Epoch 19/25\n",
      "781/781 [==============================] - 247s 317ms/step - loss: 0.4678 - accuracy: 0.8812 - val_loss: 0.5034 - val_accuracy: 0.8767\n",
      "Epoch 20/25\n",
      "781/781 [==============================] - 248s 318ms/step - loss: 0.4650 - accuracy: 0.8838 - val_loss: 0.4873 - val_accuracy: 0.8823\n",
      "Epoch 21/25\n",
      "781/781 [==============================] - 246s 315ms/step - loss: 0.4654 - accuracy: 0.8800 - val_loss: 0.5558 - val_accuracy: 0.8615\n",
      "Epoch 22/25\n",
      "781/781 [==============================] - 245s 314ms/step - loss: 0.4637 - accuracy: 0.8833 - val_loss: 0.5185 - val_accuracy: 0.8694\n",
      "Epoch 23/25\n",
      "781/781 [==============================] - 241s 309ms/step - loss: 0.4619 - accuracy: 0.8822 - val_loss: 0.5509 - val_accuracy: 0.8588\n",
      "Epoch 24/25\n",
      "781/781 [==============================] - 258s 330ms/step - loss: 0.4647 - accuracy: 0.8807 - val_loss: 0.4919 - val_accuracy: 0.8758\n",
      "Epoch 25/25\n",
      "781/781 [==============================] - 253s 324ms/step - loss: 0.4606 - accuracy: 0.8818 - val_loss: 0.4999 - val_accuracy: 0.8743\n"
     ]
    }
   ],
   "source": [
    "#DECREASING THE LEARNING RATE\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.0005,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,\n",
    "                    verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('savedmodels/model6_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "781/781 [==============================] - 256s 328ms/step - loss: 0.4397 - accuracy: 0.8887 - val_loss: 0.4973 - val_accuracy: 0.8775\n",
      "Epoch 2/25\n",
      "781/781 [==============================] - 244s 312ms/step - loss: 0.4261 - accuracy: 0.8954 - val_loss: 0.4822 - val_accuracy: 0.8821\n",
      "Epoch 3/25\n",
      "781/781 [==============================] - 254s 325ms/step - loss: 0.4199 - accuracy: 0.8945 - val_loss: 0.4694 - val_accuracy: 0.8843\n",
      "Epoch 4/25\n",
      "781/781 [==============================] - 223s 285ms/step - loss: 0.4165 - accuracy: 0.8968 - val_loss: 0.4714 - val_accuracy: 0.8857\n",
      "Epoch 5/25\n",
      "781/781 [==============================] - 223s 286ms/step - loss: 0.4152 - accuracy: 0.8965 - val_loss: 0.4846 - val_accuracy: 0.8823\n",
      "Epoch 6/25\n",
      "781/781 [==============================] - 223s 286ms/step - loss: 0.4081 - accuracy: 0.8981 - val_loss: 0.4810 - val_accuracy: 0.8803\n",
      "Epoch 7/25\n",
      "781/781 [==============================] - 234s 300ms/step - loss: 0.4068 - accuracy: 0.8979 - val_loss: 0.4573 - val_accuracy: 0.8889\n",
      "Epoch 8/25\n",
      "781/781 [==============================] - 221s 283ms/step - loss: 0.4116 - accuracy: 0.8957 - val_loss: 0.4665 - val_accuracy: 0.8822\n",
      "Epoch 9/25\n",
      "781/781 [==============================] - 235s 301ms/step - loss: 0.4006 - accuracy: 0.8990 - val_loss: 0.4542 - val_accuracy: 0.8900\n",
      "Epoch 10/25\n",
      "781/781 [==============================] - 239s 306ms/step - loss: 0.4030 - accuracy: 0.8975 - val_loss: 0.4706 - val_accuracy: 0.8846\n",
      "Epoch 11/25\n",
      "781/781 [==============================] - 241s 309ms/step - loss: 0.4012 - accuracy: 0.8995 - val_loss: 0.4600 - val_accuracy: 0.8878\n",
      "Epoch 12/25\n",
      "781/781 [==============================] - 241s 308ms/step - loss: 0.3979 - accuracy: 0.8994 - val_loss: 0.4731 - val_accuracy: 0.8863\n",
      "Epoch 13/25\n",
      "781/781 [==============================] - 240s 308ms/step - loss: 0.3926 - accuracy: 0.9007 - val_loss: 0.4538 - val_accuracy: 0.8899\n",
      "Epoch 14/25\n",
      "781/781 [==============================] - 240s 308ms/step - loss: 0.3979 - accuracy: 0.8981 - val_loss: 0.4626 - val_accuracy: 0.8875\n",
      "Epoch 15/25\n",
      "781/781 [==============================] - 241s 308ms/step - loss: 0.3958 - accuracy: 0.8998 - val_loss: 0.4453 - val_accuracy: 0.8917\n",
      "Epoch 16/25\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 0.3988 - accuracy: 0.8990 - val_loss: 0.4447 - val_accuracy: 0.8881\n",
      "Epoch 17/25\n",
      "781/781 [==============================] - 240s 307ms/step - loss: 0.3898 - accuracy: 0.9016 - val_loss: 0.4917 - val_accuracy: 0.8764\n",
      "Epoch 18/25\n",
      "781/781 [==============================] - 238s 304ms/step - loss: 0.3927 - accuracy: 0.9000 - val_loss: 0.4513 - val_accuracy: 0.8886\n",
      "Epoch 19/25\n",
      "781/781 [==============================] - 239s 306ms/step - loss: 0.3903 - accuracy: 0.8998 - val_loss: 0.4430 - val_accuracy: 0.8895\n",
      "Epoch 20/25\n",
      "781/781 [==============================] - 240s 307ms/step - loss: 0.3863 - accuracy: 0.9013 - val_loss: 0.4607 - val_accuracy: 0.8829\n",
      "Epoch 21/25\n",
      "781/781 [==============================] - 240s 308ms/step - loss: 0.3893 - accuracy: 0.8995 - val_loss: 0.4965 - val_accuracy: 0.8764\n",
      "Epoch 22/25\n",
      "781/781 [==============================] - 240s 308ms/step - loss: 0.3930 - accuracy: 0.8993 - val_loss: 0.4719 - val_accuracy: 0.8819\n",
      "Epoch 23/25\n",
      "781/781 [==============================] - 243s 311ms/step - loss: 0.3869 - accuracy: 0.9023 - val_loss: 0.4566 - val_accuracy: 0.8882\n",
      "Epoch 24/25\n",
      "781/781 [==============================] - 241s 309ms/step - loss: 0.3848 - accuracy: 0.9019 - val_loss: 0.4562 - val_accuracy: 0.8870\n",
      "Epoch 25/25\n",
      "781/781 [==============================] - 241s 308ms/step - loss: 0.3822 - accuracy: 0.9019 - val_loss: 0.4606 - val_accuracy: 0.8841\n"
     ]
    }
   ],
   "source": [
    "#DECREASING THE LEARNING RATE\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.00025,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,\n",
    "                    verbose=1,validation_data=(x_test,y_test))\n",
    "model.save_weights('savedmodels/model6_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 88.41%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
